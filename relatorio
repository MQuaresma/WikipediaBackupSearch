*Introdução:
	Projeto realizado no âmbito da cadeira de LI3 que consiste no desenvolvimento, em C, de um programa que responda a um conjunto de queries relativas a snapshots do site Wikipédia. O produto final deverá ter em conta não só a correção das suas respostas às queries mas também o tempo que demora a obter as mesmas.

*Desenvolvimento:

**Bibliotecas
***libxml2
    Na realização do trabalho foi utilizada a biblioteca libxml2, por forma a automatizar o parsing de ficheiros xml.

**Filosofia de desenvolvimento
     O código foi desenvolvido tendo em mente que a maior parte do trabalho podia ser feito na função load permitindo assim a minimização do tempo de resposta às queries mas mantendo, ainda assim, o seu tempo de execução baixo. Para isto foi tido em conta a possibilidade de que nem todas as queries seriam efetuadas e, por isso, apenas foram calculados os valores que tivessem o mínimo de impacto adicional na performance , isto é, valores que podiam ser calculados pela simples travessia da árvore gerada pela biblioteca libmlx2. Sendo assim, queries de ordenação com base em valores que não os usados para esse efeito (id de contribuidor vs nro de contribuidor do mesmo) são calculadas quando chamadas enquanto que queries em que a resposta são valores que podem ser calculados pelo simples processamento dos ficheiros xml possuem os valores já calculados (nro de artigos totais/unicos) ou as estruturas optimizadas para a execução das mesmas (consulta de nome de contribuidor).

**Estruturas de Dados
    Na escolha das estruturas de dados a utilizar optámos por escolher estruturas que nos oferecessem um tempo de consulta/inserção/remoção mais detrimento da quantidade de memória utilizada. Exemplo disto, e como iremos referir, é a estrutura utilizada para armazenar informação relativa aos contribuidores que, a troco da quantidade de memória ocupada, permite, na maioria dos casos, manter os tempos de consulta/inserção/remoção na ordem logarítimca. Esta opção foi tomada na assunção de que, ainda que o hiato processador-memória seja um dos grandes bootlenecks atuais, a quantidade de cache existente na maioria dos processadores atuais já permite o uso de estruturas como estas sem que haja uma perda de performance em relação a estruturas mais simples.

***Estrutura Principal(struct TCD_istruct):
	A estrutura principal(struct TCD_istruct) utilizada consiste em duas sub-estruturas, uma tabela de hash que guarda informação sobre os artigos(struct articTable) e uma árvore binária (de procura)nea) que quarda a informação relativa aos contribuidores (struct contribTree). A escolha desta estrutura baseia-se no facto de que, face às queries apresentadas, a relação entre artigos e  Esta divisão deve-se a termos entendido que podiamos responder às interrogações 4 e 5 independentemente das restantes interrogações, bem como responder às interrogações 3,6,7,8,9,10 com uma só estrutura. A estrutura é ainda constituída por dois long's que guardam o número de artigos únicos(artUn) e o número de artigos totais(artTot) que são calculados à medida que os snapshots vão sendo processados, permitindo assim que as respotas às duas primeiras queires sejam efetuadas em tempo (quase instantaneo) constante e tornando assim negligenciavel o tempo de cpu adicional requerido para o seu cálculo.
	  
****Estrutura dos artigos(struct articTable):
    Como já foi referido a estrutura utilizada para a informação relativa aos artigos é uma tabela de hash. Como método de tratamento de colisões escolhemos usar closed addressing visto que, apesar da estrutura adicional que requere (lista ligada), trata-se de uma forma mais simples de tratamento de colisões do que open addressing que introduziria complexidade desnecessária.
	Nesta estrutura recorremos a dois long's para armazenar o número de artigos(entradas) da hash table (nArt) bem como o tamanho da mesma(size). Estes dois valores sao usados no calculo do factor de carga da tabela de modo a sabermos quando necessita de ser redimensionada, permitindo assim a manutenção de um tempo amortizado (constante) nas operações de consulta, inserçao e remoçao. 
		
*****Artigo(struct articleInfo):
    Cada estrutura artigo quarda o id do artigo (long id) de modo a ser possivel responder às (interrogações 6,8 e 10), bem como o seu título mais recente(xmlChar *title) (interrogações 7 e 8). Tem também um dicionário com as revisões do artigo(struct revDict *), a chave corresponde ao id da revisão e o valor corresponde à altura em que esta foi efetuada(timestamp). Recorremos ainda a 3 long's (nRev,len,word) para armazenar o número de revisões no dicionário, o numero de caracteres da maior revisão efetuada e o número de palavras também da mais recente revisão.	
				
****Estrutura dos contribuidores(struct contribTree):
	Para os contribuidores recorremos a uma árvore binária de procura ordenadaordenada pelo id dos mesmos. Esta escolhe foi feita tendo em mente um tempo de resposta reduzido às operações de consulta de contribuidores(interrogação 5) em detrimento da consulta dos 10 contribuidores mais ativos (interrogaçao 10) que, num cenário real, seria executada menos frequentemente a primera já que, num cenário real, a resposta não varia para o mesmo grupo de snapshots. Cada nó da árvore armazena o id do contribuidor, o nome do contribuidor (xmlChar *nome) e o número de revisões realizadas pelo mesmo(int nRev).

	--Interrogações:
		--Interrogação 1:
		--Interrogação 2:
		--Interrogação 3:
		--Interrogação 4:
		--Interrogação 5:
		--Interrogação 6:
		--Interrogação 7:
		--Interrogação 8:
		--Interrogação 9:
		--Interrogação 10:

--Conclusão:
	Em conlusão, achamos que realizamos um bom trabalho e um bom programa visto os tempos de execução do mesmo serem próximos ou até melhores(em alguns casos) do que os tempos disponibilizados pelos docentes.
